{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo notebook for accessing HLS data on Azure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides an example of accessing HLS (Harmonized Landsat Sentinel-2) data from blob storage on Azure, extracting image metadata using [GDAL](https://gdal.org), and displaying an image using GDAL and [rasterio](https://github.com/mapbox/rasterio).\n",
    "\n",
    "HLS data are stored in the East US 2 data center, so this notebook will run more efficiently on the Azure compute located in East US 2.  You don't want to download hundreds of terabytes to your laptop! If you are using HLS data for environmental science applications, consider applying for an [AI for Earth grant](http://aka.ms/ai4egrants) to support your compute requirements.\n",
    "\n",
    "HLS data on Azure are managed by [Ag-Analytics](https://analytics.ag). Ag-Analytics also provides an [API](https://ag-analytics.portal.azure-api.net/docs/services/harmonized-landsat-sentinel-service/operations/hls-service) which allows the caller to query to perform spatial queries over the HLS archive, as well as querying for additional data such as cloud cover and Normalized Difference Vegetation Index (NDVI).  Ag-Analytics also provides an [API](https://aganalyticsapimanagementservice.portal.azure-api.net/docs/services/hls-service/operations/post-detect-tiles?) to retrieve tile IDs matching spatial queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard-ish packages\n",
    "import requests\n",
    "import re\n",
    "import numpy as np\n",
    "import urllib\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Less standard, but all of the following are pip- or conda-installable\n",
    "import rasterio\n",
    "\n",
    "# pip install azure-storage-blob\n",
    "from azure.storage.blob import ContainerClient\n",
    "\n",
    "from osgeo import gdal,osr\n",
    "\n",
    "# Storage locations are documented at http://aka.ms/ai4edata-hls\n",
    "hls_container_name = 'hls'\n",
    "hls_account_name = 'hlssa'\n",
    "hls_account_url = 'https://' + hls_account_name + '.blob.core.windows.net/'\n",
    "hls_blob_root = hls_account_url + hls_container_name\n",
    "\n",
    "# This file is provided by NASA; it indicates the lat/lon extents of each\n",
    "# hls tile.\n",
    "#\n",
    "# The file originally comes from:\n",
    "#\n",
    "# https://hls.gsfc.nasa.gov/wp-content/uploads/2016/10/S2_TilingSystem2-1.txt\n",
    "#\n",
    "# ...but as of 8/2019, there is a bug with the column names in the original file, so we\n",
    "# access a copy with corrected column names.\n",
    "hls_tile_extents_url = 'https://ai4edatasetspublicassets.blob.core.windows.net/assets/S2_TilingSystem2-1.txt'\n",
    "\n",
    "# Load this file into a table, where each row is:\n",
    "#\n",
    "# Tile ID, Xstart, Ystart, UZ, EPSG, MinLon, MaxLon, MinLon, MaxLon\n",
    "print('Reading tile extents...')\n",
    "s = requests.get(hls_tile_extents_url).content\n",
    "hls_tile_extents = pd.read_csv(io.StringIO(s.decode('utf-8')),delimiter=r'\\s+')\n",
    "print('Read tile extents for {} tiles'.format(len(hls_tile_extents)))\n",
    "\n",
    "hls_container_client = ContainerClient(account_url=hls_account_url, \n",
    "                                         container_name=hls_container_name,\n",
    "                                         credential=None)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hls_tile(blob_url):\n",
    "    \"\"\"\n",
    "    Given a URL pointing to an HLS image in blob storage, load that image via GDAL\n",
    "    and return both data and metadata.\n",
    "    \"\"\"    \n",
    "    \n",
    "    formatted_gdal_bloburl='/{}/{}'.format('vsicurl',blob_url)\n",
    "    \n",
    "    tile_open = gdal.Open(formatted_gdal_bloburl)\n",
    "    data = tile_open.GetRasterBand(1)\n",
    "    ndv,xsize,ysize = data.GetNoDataValue(),tile_open.RasterXSize,tile_open.RasterYSize\n",
    "    \n",
    "    projection = osr.SpatialReference()\n",
    "    projection.ImportFromWkt(tile_open.GetProjectionRef())\n",
    "    \n",
    "    datatype = data.DataType\n",
    "    datatype = gdal.GetDataTypeName(datatype)  \n",
    "    data_array = data.ReadAsArray()\n",
    "\n",
    "    return ndv,xsize,ysize,projection,data_array\n",
    "\n",
    "\n",
    "def list_available_tiles(prefix):\n",
    "    \"\"\"\n",
    "    List all blobs in an Azure blob container matching a prefix.  \n",
    "    \n",
    "    We'll use this to query tiles by location and year.\n",
    "    \"\"\"\n",
    "    \n",
    "    files = []\n",
    "    generator = hls_container_client.list_blobs(name_starts_with=prefix)\n",
    "    for blob in generator:\n",
    "        files.append(blob.name)\n",
    "    return files\n",
    "\n",
    "    \n",
    "def lat_lon_to_hls_tile_id(lat,lon):\n",
    "    \"\"\"\n",
    "    Get the hls tile ID for a given lat/lon coordinate pair.\n",
    "    \"\"\"  \n",
    "    \n",
    "    found_matching_tile = False\n",
    "\n",
    "    for i_row,row in hls_tile_extents.iterrows():\n",
    "        found_matching_tile = lat >= row.MinLat and lat <= row.MaxLat \\\n",
    "        and lon >= row.MinLon and lon <= row.MaxLon\n",
    "        if found_matching_tile:\n",
    "            break\n",
    "    \n",
    "    if not found_matching_tile:\n",
    "        return None\n",
    "    else:\n",
    "        return row.TilID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find a tile for a given location and date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify a location and year of interest\n",
    "lat = 47.6101; lon = -122.2015 # Bellevue, WA\n",
    "\n",
    "year = '2019'\n",
    "daynum = '109'    # 1-indexed day-of-year\n",
    "folder = 'S309'   # 'S309' for Sentinel, 'L309' for Landsat\n",
    "product = 'S30'   # 'S30' for Sentinel, 'L30' for Landsat\n",
    "year = '2019'\n",
    "\n",
    "tile_id = lat_lon_to_hls_tile_id(lat,lon)\n",
    "assert tile_id is not None, 'Invalid lat/lon'\n",
    "prefix = folder + '/HLS.' + product + '.T' + tile_id + '.' + year\n",
    "\n",
    "print('Finding tiles with prefix {}'.format(prefix))\n",
    "matches = list_available_tiles(prefix)\n",
    "assert len(matches) > 0, 'No matching tiles'\n",
    "\n",
    "blob_name = matches[0]\n",
    "print('Found {} matching tiles, using file {}'.format(len(matches),blob_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ...or build a tile path from components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat = 47.6101; lon = -122.2015 # Bellevue, WA\n",
    "\n",
    "year    = '2019'\n",
    "daynum  = '001'   # 1-indexed day-of-year\n",
    "folder  = 'S30'   # 'S30' for Sentinel, 'L30' for Landsat\n",
    "product = 'S30'   # 'S30' for Sentinel, 'L30' for Landsat\n",
    "band    = '01'\n",
    "tile_id = '10TET' # See hls.gsfc.nasa.gov/wp-content/uploads/2016/10/S2_TilingSystem2-1.txt\n",
    "version = 'v1.4'  # Currently always v1.4\n",
    "\n",
    "blob_name = folder + '/HLS.' + product + '.T' + tile_id + '.' + year + daynum + '.' + version \\\n",
    "    + '_' + band + '.tif'\n",
    "\n",
    "print('Using file {}'.format(blob_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Access one band of the selected image using GDAL's virtual file system ([vsicurl](https://gdal.org/user/virtual_file_systems.html#vsicurl-http-https-ftp-files-random-access))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gdal.SetConfigOption('GDAL_HTTP_UNSAFESSL', 'YES')\n",
    "blob_url = hls_blob_root + '/' + blob_name\n",
    "print('Reading tile from {}'.format(blob_url))\n",
    "ndv,xsize,ysize,projection,data_array = get_hls_tile(blob_url)\n",
    "\n",
    "print('No-data value: {}'.format(ndv))\n",
    "print('\\nSize: {},{}'.format(xsize,ysize))\n",
    "print('\\nProjection:\\n{}'.format(projection))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display a Sentinel-2 image using rasterio and vsicurl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bands 2, 3, and 4 are B, G, and R in Sentinel-2 HLS images\n",
    "\n",
    "base_url = '/vsicurl/' + hls_blob_root + '/' + blob_name\n",
    "band2_url = re.sub('_(\\d+).tif','_02.tif',base_url)\n",
    "band3_url = re.sub('_(\\d+).tif','_03.tif',base_url)\n",
    "band4_url = re.sub('_(\\d+).tif','_04.tif',base_url)\n",
    "print('Reading bands from:\\n{}\\n{}\\n{}'.format(band2_url,band3_url,band4_url))\n",
    "\n",
    "band2 = rasterio.open(band2_url)\n",
    "band3 = rasterio.open(band3_url)\n",
    "band4 = rasterio.open(band4_url)\n",
    "\n",
    "norm_value = 2000\n",
    "image_data = []\n",
    "for band in [band4,band3,band2]:\n",
    "    band_array = band.read(1)\n",
    "    band_array = band_array / norm_value\n",
    "    image_data.append(band_array)\n",
    "    band.close()\n",
    "\n",
    "rgb = np.dstack((image_data[0],image_data[1],image_data[2]))\n",
    "np.clip(rgb,0,1,rgb)\n",
    "plt.imshow(rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the jpeg thumbnail from a COG file without reading the whole file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_urls = [band4_url, band3_url, band2_url]\n",
    "\n",
    "thumbnail_data = []\n",
    "\n",
    "# url = rgb_urls[0]\n",
    "for url in rgb_urls:\n",
    "    \n",
    "    # From:\n",
    "    #\n",
    "    # https://automating-gis-processes.github.io/CSC/notebooks/L5/read-cogs.html\n",
    "    with rasterio.open(url) as raster:\n",
    "        \n",
    "        # List of overviews from largest to smallest\n",
    "        oviews = raster.overviews(1)\n",
    "    \n",
    "        # Retrieve the second-largest thumbnail\n",
    "        decimation_level = oviews[1]\n",
    "        h = int(raster.height/decimation_level)\n",
    "        w = int(raster.width/decimation_level)\n",
    "        \n",
    "        thumbnail_channel = raster.read(1, out_shape=(1, h, w)) / norm_value\n",
    "        thumbnail_data.append(thumbnail_channel)\n",
    "\n",
    "rgb = np.dstack((thumbnail_data[0],thumbnail_data[1],thumbnail_data[2]))\n",
    "np.clip(rgb,0,1,rgb)\n",
    "plt.imshow(rgb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
